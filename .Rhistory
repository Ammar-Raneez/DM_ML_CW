mlp_df <- mlp_model[["net"]][["data"]]
View(mlp_df)
View(scaled_exchange_data_hidden_1_shifted)
View(scaled_exchange_data)
View(train_hidden_2)
as.ts(train_hidden_2[,2]
as.ts(train_hidden_2[,2])
as.ts(train_hidden_2[,2])
View(test_hidden_2)
View(test_hidden_1)
times <- as.ts(train_hidden_2[,2])
times
mlp_model <- mlp(times, hd = c(4, 4), lags = 1)
View(mlp_model)
mlp_model[["y"]]
View(nn_best_double)
View(nn_best_single.test_prediction)
mlp_model[["net"]][["data"]]
View(mlp_df)
nn_best_single <- neuralnet(X1 ~ Y, data = mlp_df, hidden = c(4), act.fct = "logistic", err.fct = "sse", lifesign = "full", learningrate = 0.08, rep = 10, linear.output = T)
nn_best_single.test_prediction <- predict(nn_best_single, test_hidden_1)
View(nn_best_single)
nn_best_single <- neuralnet(Y ~ X1, data = mlp_df, hidden = c(4), act.fct = "logistic", err.fct = "sse", lifesign = "full", learningrate = 0.08, rep = 10, linear.output = T)
nn_best_single <- neuralnet(Y ~ X1, data = mlp_df, hidden = c(4), act.fct = "logistic", err.fct = "sse", lifesign = "full", learningrate = 0.08, rep = 10, linear.output = T)
View(nn_best_single)
#nn_best_single.test_prediction <- predict(nn_best_single, test_hidden_1)
frc <- forecast(nn_best_single, h=100)
nn_best_single.test_prediction <- predict(nn_best_single, test_hidden_1)
nn_best_single.test_prediction <- predict(nn_best_single, test_hidden_1[,2])
test_hidden_1[,2]
View(test_hidden_2)
nn_best_single.test_prediction <- predict(nn_best_single, test_hidden_1[,2])
colnames(mlp_df) <- c("rate", "rate_1")
View(mlp_df)
nn_best_single <- neuralnet(rate ~ rate_1, data = mlp_df, hidden = c(4), act.fct = "logistic", err.fct = "sse", lifesign = "full", learningrate = 0.08, rep = 10, linear.output = T)
nn_best_single.test_prediction <- predict(nn_best_single, test_hidden_1)
# plot graph of best network
plot(test_hidden_1[, 1], type = "l", col = "blue", lwd = 2, xlab = "index", ylab = "Rates")
lines(nn_best_single.test_prediction, type = "l", col = "red", lwd = 2)
title("AR(1) Time Series - Single Hidden Layer")
legend("bottomright", legend = c("Actual", "Predicted"), col = c("blue", "red"), bty = "n", cex=1, lwd = 5, text.font = 7)
times <- as.ts(train_hidden_2[,2])
mlp_model <- mlp(times, hd = c(4, 4), lags = 1)
forecasted <- forecast(mlp_model, h=100)
plot(forecasted)
lines(scaled_exchange_data_ts)
plot(forecasted)
lines(test_hidden_2[, 1])
mlp_model <- mlp(times, hd = c(4), lags = 1)
View(mlp_model)
View(nn_best_single.test_prediction)
View(nn_best_single.test_prediction)
mlp_model[["net"]][["response"]]
install.packages("rsnns")
y
install.packages("RSNNS")
library(RSNNS)
mlp_model <- mlp(as.ts(train_hidden_2[,1]), times, hd = c(4), lags = 1)
View(mlp_model)
forecasted <- forecast(mlp_model, h=100)
x <- predict(mlp_model, test_hidden_2)
x <- predict(mlp_model, test_hidden_2[,2])
mlp_model <- mlp(as.ts(train_hidden_2[,2]), times, hd = c(4), lags = 1)
x <- predict(mlp_model, test_hidden_2[,2])
y_times <-as.ts(train_hidden_2[,1])
mlp_model <- mlp(x = times, y = y_times, hd = c(4), lags = 1)
x <- predict(mlp_model, test_hidden_2[,2])
library(nnfor)
mlp_model <- mlp(x = times, y = y_times, hd = c(4), lags = 1)
x <- predict(mlp_model, test_hidden_2[,2])
View(mlp_model)
mlp_model <- mlp(x = times, y = y_times, hd = c(4), lags = 1)
View(mlp_model)
mlp_model <- mlp(times, hd = c(4), lags = 1)
library(nnfor)
mlp_model <- mlp(times, hd = c(4), lags = 1)
library(readxl)
library(neuralnet)
library(fpp2)
library(ggplot2)
library(Metrics)
library(useful)
library(nnfor)
library(forecast)
# import dataset
exchange_data <- read_excel("../../ExchangeUSD.xlsx")
# remove unneeded days column
exchange_data <- exchange_data[c(-2)]
# convert to time-series, so the date is also in a numeric format
exchange_data <- ts(exchange_data)
exchange_data <- as.data.frame(exchange_data)
# rename col names for easiness
colnames(exchange_data) <- c("date", "rate")
# scale the data
maxs <- apply(exchange_data, 2, max)
mins <- apply(exchange_data, 2, min)
scaled_exchange_data <- as.data.frame(scale(exchange_data, center = mins, scale = maxs - mins))
# plot partial autocorrelation plot to check for optimum order of AR ~ however many orders
# will be tested upon
pacf(scaled_exchange_data[, 2])
# plot the rates to check whether stationary
plot(exchange_data[c(2)])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_2_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_2_shifted <- scaled_exchange_data_hidden_2_shifted[c(-1)]
train_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[0:400, ])
test_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[401:500, ])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_1_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_1_shifted <- scaled_exchange_data_hidden_1_shifted[c(-1)]
train_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[0:400, ])
test_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[401:500, ])
times <- as.ts(train_hidden_2[,2])
mlp_model <- mlp(times, hd = c(4), lags = 1)
# import dataset
exchange_data <- read_excel("../../ExchangeUSD.xlsx")
library(readxl)
library(neuralnet)
library(fpp2)
library(ggplot2)
library(Metrics)
library(useful)
library(nnfor)
library(forecast)
# remove unneeded days column
exchange_data <- exchange_data[c(-2)]
# import dataset
exchange_data <- read_excel("../../ExchangeUSD.xlsx")
# convert to time-series, so the date is also in a numeric format
exchange_data <- ts(exchange_data)
exchange_data <- as.data.frame(exchange_data)
# rename col names for easiness
colnames(exchange_data) <- c("date", "rate")
# scale the data
maxs <- apply(exchange_data, 2, max)
mins <- apply(exchange_data, 2, min)
scaled_exchange_data <- as.data.frame(scale(exchange_data, center = mins, scale = maxs - mins))
# plot partial autocorrelation plot to check for optimum order of AR ~ however many orders
# will be tested upon
pacf(scaled_exchange_data[, 2])
# plot the rates to check whether stationary
plot(exchange_data[c(2)])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_2_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_2_shifted <- scaled_exchange_data_hidden_2_shifted[c(-1)]
train_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[0:400, ])
test_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[401:500, ])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_1_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_1_shifted <- scaled_exchange_data_hidden_1_shifted[c(-1)]
train_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[0:400, ])
test_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[401:500, ])
times <- as.ts(train_hidden_2[,2])
mlp_model <- mlp(times, hd = c(4), lags = 1)
View(mlp_model)
times
# import dataset
exchange_data <- read_excel("../../ExchangeUSD.xlsx")
# remove unneeded days column
exchange_data <- exchange_data[c(-2)]
# convert to time-series, so the date is also in a numeric format
exchange_data <- ts(exchange_data)
exchange_data <- as.data.frame(exchange_data)
# rename col names for easiness
colnames(exchange_data) <- c("date", "rate")
# scale the data
maxs <- apply(exchange_data, 2, max)
mins <- apply(exchange_data, 2, min)
scaled_exchange_data <- as.data.frame(scale(exchange_data, center = mins, scale = maxs - mins))
# plot partial autocorrelation plot to check for optimum order of AR ~ however many orders
# will be tested upon
pacf(scaled_exchange_data[, 2])
# plot the rates to check whether stationary
plot(exchange_data[c(2)])
x <- predict(mlp_model, test_hidden_2[,2])
forecasted <- forecast(mlp_model, h=100)
plot(forecasted)
lines(test_hidden_2[, 1])
# import dataset
exchange_data <- read_excel("../../ExchangeUSD.xlsx")
# remove unneeded days column
exchange_data <- exchange_data[c(-2)]
# convert to time-series, so the date is also in a numeric format
exchange_data <- ts(exchange_data)
exchange_data <- as.data.frame(exchange_data)
# rename col names for easiness
colnames(exchange_data) <- c("date", "rate")
# scale the data
maxs <- apply(exchange_data, 2, max)
mins <- apply(exchange_data, 2, min)
scaled_exchange_data <- as.data.frame(scale(exchange_data, center = mins, scale = maxs - mins))
# plot partial autocorrelation plot to check for optimum order of AR ~ however many orders
# will be tested upon
pacf(scaled_exchange_data[, 2])
# plot the rates to check whether stationary
plot(exchange_data[c(2)])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_2_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_2_shifted <- scaled_exchange_data_hidden_2_shifted[c(-1)]
train_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[0:400, ])
test_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[401:500, ])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_1_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_1_shifted <- scaled_exchange_data_hidden_1_shifted[c(-1)]
train_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[0:400, ])
test_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[401:500, ])
times <- as.ts(train_hidden_2[,2])
mlp_model <- mlp(times, hd = c(4), lags = 1)
x <- predict(mlp_model, test_hidden_2[,2])
forecasted <- forecast(mlp_model, h=100)
plot(forecasted)
lines(test_hidden_2[, 1])
lines(times)
lines(scaled_exchange_data)
lines(scaled_exchange_data[,1])
lines(scaled_exchange_data[,2])
plot(forecasted)
lines(scaled_exchange_data[,2])
View(mlp_model)
View(train_hidden_1)
mlp_model[["y"]]
times <- as.ts(exchange_data[,2])
mlp_model <- mlp(times, hd = c(4), lags = 1)
library(nnfor)
mlp_model <- mlp(times, hd = c(4), lags = 1)
View(mlp_model)
mlp_model[["y"]]
mlp_model[["fitted"]]
View(mlp_model)
train_hidden_2
times <- as.ts(train_hidden_2[,2])
mlp_model <- mlp(times, hd = c(4), lags = 1)
View(mlp_model)
mlp_model[["y"]]
median(mlp_model[["y"]])
mlp_model <- mlp(times, hd = c(4), lags = 1, comb = "mean")
View(mlp_model)
mlp_model <- mlp(times, hd = c(4), lags = 1, comb = "mean")
View(mlp_model)
### BEST SINGLE HIDDEN LAYER NETWORK
set.seed(104)
nn_best_single <- neuralnet(rate ~ rate_1, data = mlp_df, hidden = c(4), act.fct = "logistic", err.fct = "sse", lifesign = "full", learningrate = 0.08, rep = 10, linear.output = T)
library(neuralnet)
nn_best_single <- neuralnet(rate ~ rate_1, data = mlp_df, hidden = c(4), act.fct = "logistic", err.fct = "sse", lifesign = "full", learningrate = 0.08, rep = 10, linear.output = T)
nn_best_single <- neuralnet(rate ~ rate_1, data = train_hidden_1, hidden = c(4), act.fct = "logistic", err.fct = "sse", lifesign = "full", learningrate = 0.08, rep = 10, linear.output = T)
nn_best_single.test_prediction <- predict(nn_best_single, test_hidden_1)
plot(nn_best_single)
View(nn_best_single)
View(train_hidden_1)
mlp_model <- mlp(times, hd = c(4), lags = 1, comb = "mean", difforder = 0)
View(mlp_model)
mlp_model <- mlp(times, hd = c(4), lags = 1, comb = "mean", difforder = 0)
View(mlp_model)
mlp_model[["difforder"]]
View(mlp_model)
library(readxl)
library(neuralnet)
library(fpp2)
library(ggplot2)
library(Metrics)
library(useful)
library(nnfor)
library(forecast)
# import dataset
exchange_data <- read_excel("../../ExchangeUSD.xlsx")
# remove unneeded days column
exchange_data <- exchange_data[c(-2)]
# convert to time-series, so the date is also in a numeric format
exchange_data <- ts(exchange_data)
exchange_data <- as.data.frame(exchange_data)
# rename col names for easiness
colnames(exchange_data) <- c("date", "rate")
# scale the data
maxs <- apply(exchange_data, 2, max)
mins <- apply(exchange_data, 2, min)
scaled_exchange_data <- as.data.frame(scale(exchange_data, center = mins, scale = maxs - mins))
# plot partial autocorrelation plot to check for optimum order of AR ~ however many orders
# will be tested upon
pacf(scaled_exchange_data[, 2])
# plot the rates to check whether stationary
plot(exchange_data[c(2)])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_2_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_2_shifted <- scaled_exchange_data_hidden_2_shifted[c(-1)]
train_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[0:400, ])
test_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[401:500, ])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_1_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_1_shifted <- scaled_exchange_data_hidden_1_shifted[c(-1)]
train_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[0:400, ])
test_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[401:500, ])
View(exchange_data)
x <- linscale(exchange_data$rate, minmax=list("mn"=-.8,"mx"=0.8))
View(x)
times <- as.ts(train_hidden_2[,2])
mlp_model <- mlp(times, hd = c(4), lags = 1, comb = "mean", difforder = 0)
View(mlp_model)
scaled_exchange_data <- as.data.frame(scale(exchange_data, center = mins, scale = maxs - mins))
scaled_exchange_data$rate <- linscale(exchange_data$rate, minmax=list("mn"=-.8,"mx"=0.8))
View(scaled_exchange_data)
View(scaled_exchange_data)
scaled_exchange_data <- as.data.frame(scale(exchange_data, center = mins, scale = maxs - mins))
scaled_exchange_data <- linscale(exchange_data$rate, minmax=list("mn"=-.8,"mx"=0.8))
View(scaled_exchange_data)
scaled_exchange_data[["x"]]
mlp_model[["net"]][["covariate"]]
scaled_exchange_data <- as.data.frame(scale(exchange_data, center = mins, scale = maxs - mins))
View(scaled_exchange_data)
scaled_rates <- linscale(exchange_data$rate, minmax=list("mn"=-.8,"mx"=0.8))
scaled_exchange_data$rate <- scaled_rates$x
View(scaled_exchange_data)
# plot partial autocorrelation plot to check for optimum order of AR ~ however many orders
# will be tested upon
pacf(scaled_exchange_data[, 2])
# plot the rates to check whether stationary
plot(exchange_data[c(2)])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_2_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_2_shifted <- scaled_exchange_data_hidden_2_shifted[c(-1)]
train_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[0:400, ])
test_hidden_2 <- na.omit(scaled_exchange_data_hidden_2_shifted[401:500, ])
# Optimal Input vector - AR(1)
scaled_exchange_data_hidden_1_shifted <- shift.column(scaled_exchange_data, columns = "rate", newNames = "rate_1", len = 1, up = F)
scaled_exchange_data_hidden_1_shifted <- scaled_exchange_data_hidden_1_shifted[c(-1)]
train_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[0:400, ])
test_hidden_1 <- na.omit(scaled_exchange_data_hidden_1_shifted[401:500, ])
### BEST SINGLE HIDDEN LAYER NETWORK
set.seed(104)
nn_best_single <- neuralnet(rate ~ rate_1, data = train_hidden_1, hidden = c(4), act.fct = "logistic", err.fct = "sse", lifesign = "full", learningrate = 0.08, rep = 10, linear.output = T)
nn_best_single.test_prediction <- predict(nn_best_single, test_hidden_1)
# plot graph of best network
plot(test_hidden_1[, 1], type = "l", col = "blue", lwd = 2, xlab = "index", ylab = "Rates")
lines(nn_best_single.test_prediction, type = "l", col = "red", lwd = 2)
title("AR(1) Time Series - Single Hidden Layer")
legend("bottomright", legend = c("Actual", "Predicted"), col = c("blue", "red"), bty = "n", cex=1, lwd = 5, text.font = 7)
x <- predict(mlp_model, test_hidden_2[,2])
View(scaled_exchange_data_hidden_1_shifted)
View(train_hidden_1)
len(train_hidden_1)
length(train_hidden_1)
length(train_hidden_1[,1])
forecast(nn_best_single)
forecast(mlp_model)
forecast(mlp_model$net)
forecast(mlp_model$hd)
forecast(mlp_model$lags)
forecast(mlp_model$y)
forecast(mlp_model$fitted)
forecast(mlp_model$sdummy)
forecast(nn_best_single$model.list)
forecast(nn_best_single$call)
forecast(nn_best_single$response)
forecast(nn_best_single$covariate)
forecast(nn_best_single$net.result)
forecast(nn_best_single$result.matrix)
forecast(nn_best_single$startweights)
forecast(nn_best_single$generalized.weights)
forecast(nn_best_single$weights)
forecast(nn_best_single$weights)
forecast(nn_best_single$net.result)
forecast(nn_best_single$exclude)
forecast(nn_best_single$linear.output)
forecast(nn_best_single$act.fct())
forecast(nn_best_single$err.fct())
install.packages("maltese")
library(tidyverse)
library(maltese)
library(neuralnet)
library(dummy)
data("r_enwiki", package = "maltese")
library(maltese)
install.packages("maltese")
install.packages("maltese")
library(dummy)
install.packages("dummy")
library(dummy)
data("r_enwiki", package = "maltese")
remotes::install_github("bearloga/maltese")
install.packages("remotess")
install.packages("remotes")
remotes::install_github("bearloga/maltese")
library(tidyverse)
library(maltese)
library(neuralnet)
library(dummy)
data("r_enwiki", package = "maltese")
head(r_enwiki)
View(r_enwiki)
ggplot(r_enwiki, aes(x = date, y = pageviews)) +
geom_line() +
theme_minimal() +
labs(x = "Date", y = "Pageviews",
title = "Pageviews"
)
split_point <- "2017-02-01"
table(ifelse(r_enwiki$date < split_point, "training set", "testing set"))
normalization_constants <- lapply(
list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = r_enwiki$pageviews[r_enwiki$date < split_point])
)
View(normalization_constants)
View(normalization_constants)
r_enwiki$normalized <- (r_enwiki$pageviews - normalization_constants$mean)/normalization_constants$std.dev
mlts <- mlts_transform(r_enwiki, date, normalized, p = 21, extras = TRUE, extrasAsFactors = TRUE, granularity = "day")
str(mlts)
es(mlts[, c("mlts_extras_weekday", "mlts_extras_month", "mlts_extras_monthday", "mlts_extras_week"), drop = FALSE])
mlts_dummied <- cbind(mlts, dummy(
mlts[, c("mlts_extras_weekday", "mlts_extras_month", "mlts_extras_monthday", "mlts_extras_week"),
drop = FALSE],
object = mlts_categories, int = TRUE
))
str(mlts_dummied, list.len = 30)
mlts_categories <- categories(mlts[, c("mlts_extras_weekday", "mlts_extras_month", "mlts_extras_monthday", "mlts_extras_week"), drop = FALSE])
mlts_dummied <- cbind(mlts, dummy(
mlts[, c("mlts_extras_weekday", "mlts_extras_month", "mlts_extras_monthday", "mlts_extras_week"),
drop = FALSE],
object = mlts_categories, int = TRUE
))
str(mlts_dummied, list.len = 30)
training_idx <- which(mlts_dummied$dt < split_point)
testing_idx <- which(mlts_dummied$dt >= split_point)
# Train:
set.seed(0)
nn_model <- neuralnet(
nn_formula, mlts_dummied[training_idx, c("y", nn_features)],
linear.output = TRUE, hidden = c(9, 7, 5), algorithm = "sag"
)
tail(r_enwiki, 22)
View(r_enwiki)
library(tidyverse)
library(maltese)
library(neuralnet)
library(dummy)
data("r_enwiki", package = "maltese")
head(r_enwiki)
ggplot(r_enwiki, aes(x = date, y = pageviews)) +
geom_line() +
theme_minimal() +
labs(x = "Date", y = "Pageviews",
title = "Pageviews"
)
split_point <- "2017-02-01"
table(ifelse(r_enwiki$date < split_point, "training set", "testing set"))
normalization_constants <- lapply(
list(median = median, mad = mad, mean = mean, std.dev = sd),
do.call, args = list(x = r_enwiki$pageviews[r_enwiki$date < split_point])
)
r_enwiki$normalized <- (r_enwiki$pageviews - normalization_constants$mean)/normalization_constants$std.dev
mlts <- mlts_transform(r_enwiki, date, normalized, p = 21, extras = TRUE, extrasAsFactors = TRUE, granularity = "day")
str(mlts)
mlts_categories <- categories(mlts[, c("mlts_extras_weekday", "mlts_extras_month", "mlts_extras_monthday", "mlts_extras_week"), drop = FALSE])
mlts_dummied <- cbind(mlts, dummy(
mlts[, c("mlts_extras_weekday", "mlts_extras_month", "mlts_extras_monthday", "mlts_extras_week"),
drop = FALSE],
object = mlts_categories, int = TRUE
))
str(mlts_dummied, list.len = 30)
training_idx <- which(mlts_dummied$dt < split_point)
testing_idx <- which(mlts_dummied$dt >= split_point)
# neuralnet does not support the "y ~ ." formula syntax, so we cheat:
nn_features <- grep("(mlts_lag_[0-9]+)|(mlts_extras_((weekday)|(month)|(monthday)|(week))_.*)", names(mlts_dummied), value = TRUE)
nn_formula <- as.formula(paste("y ~", paste(nn_features, collapse = " + ")))
# Train:
set.seed(0)
nn_model <- neuralnet(
nn_formula, mlts_dummied[training_idx, c("y", nn_features)],
linear.output = TRUE, hidden = c(9, 7, 5), algorithm = "sag"
)
new_data <- rbind(
tail(r_enwiki, 22),
data.frame(
date = seq(
as.Date("2017-05-17"),
as.Date("2017-05-17") + 90,
"day"
),
pageviews = NA,
normalized = NA
)
); rownames(new_data) <- NULL
for (d in 23:nrow(new_data)) {
new_mlts <- mlts_transform(
new_data[(d - 22):d, ],
date, normalized, p = 21,
extras = TRUE, extrasAsFactors = TRUE,
granularity = "day")
new_mlts <- cbind(
new_mlts[-1, ], # don't need to forecast known outcome
dummy(
new_mlts[, c("mlts_extras_weekday", "mlts_extras_month", "mlts_extras_monthday", "mlts_extras_week"),
drop = FALSE],
object = mlts_categories, int = TRUE
)[-1, ]
)
new_data$normalized[d] <- as.numeric(neuralnet::compute(
nn_model, new_mlts[, nn_features])$net.result
)
}
# Forecast on normalized scale:
nn_forecast <- as.numeric(neuralnet::compute(
nn_model, new_mlts[, nn_features])$net.result
)
new_data$pageviews <- (new_data$normalized * normalization_constants$std.dev) + normalization_constants$mean
ggplot(dplyr::filter(r_enwiki, date >= "2016-10-01"),
aes(x = date, y = pageviews)) +
geom_line() +
geom_line(aes(y = pageviews), color = "red",
data = dplyr::filter(new_data, date >= "2017-05-16")) +
theme_minimal() +
labs(x = "Date", y = "Pageviews",
title = "90 days forecast Pageviews"
)
